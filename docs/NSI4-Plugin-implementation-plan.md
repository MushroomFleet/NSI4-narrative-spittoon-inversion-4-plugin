# NSI4 Plugin Implementation Plan

## NarrativeSpittoonInversion-Plugin — Complete Build Specification

**Version**: 4.0.0
**Author**: Drift Johnson (ScuffedEpoch.com)
**Date**: 2026-02-08
**Status**: Implementation Plan — Awaiting Approval

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Architecture Overview](#2-architecture-overview)
3. [Directory Structure](#3-directory-structure)
4. [Plugin Manifest](#4-plugin-manifest)
5. [Skill: nsi4-workflow](#5-skill-nsi4-workflow)
6. [Command: /nsi4-start](#6-command-nsi4-start)
7. [Command: /nsi4-interview](#7-command-nsi4-interview)
8. [Command: /nsi4-bucket](#8-command-nsi4-bucket)
9. [Command: /nsi4-frameworks](#9-command-nsi4-frameworks)
10. [Command: /nsi4-generate](#10-command-nsi4-generate)
11. [Command: /nsi4-refine](#11-command-nsi4-refine)
12. [Command: /nsi4-export](#12-command-nsi4-export)
13. [Agent: holographic-tutor](#13-agent-holographic-tutor)
14. [Agent: bucket-builder](#14-agent-bucket-builder)
15. [Hook: Story Page Validation](#15-hook-story-page-validation)
16. [Script: NSL Converter](#16-script-nsl-converter)
17. [Reference Files](#17-reference-files)
18. [Bucket Templates](#18-bucket-templates)
19. [Implementation Sequence](#19-implementation-sequence)
20. [Testing Plan](#20-testing-plan)

---

## 1. Executive Summary

### What We're Building

A Claude Code plugin that implements the **Narrative Spittoon Inversion 4.0** (NSI4) workflow — an AI-assisted story creation methodology that generates narratives in reverse chronological order. The plugin eliminates the copy-paste prompt workflow of NSI 3.0 by integrating directly with Claude Code's file system tools.

### Key Upgrades from NSI 3.0 → 4.0

| Aspect | NSI 3.0 (Web Service) | NSI 4.0 (Claude Code Plugin) |
|--------|----------------------|------------------------------|
| Workflow | Copy-paste prompts to chat | Slash commands operate directly on files |
| File Management | Manual file creation | Automated project scaffolding + writes |
| Context Loading | User re-attaches files each turn | Plugin reads bucket files automatically |
| Validation | Manual review only | Holographic Tutor agent on demand |
| Templates | User copies from docs | `/nsi4-start` copies templates automatically |
| NSL Support | None | Full import/export via Python script |
| Frameworks | User installs manually | `/nsi4-frameworks` installs + configures |

### Component Summary

- **1 Skill**: `nsi4-workflow` — Core methodology knowledge
- **7 Commands**: `/nsi4-start`, `/nsi4-interview`, `/nsi4-bucket`, `/nsi4-frameworks`, `/nsi4-generate`, `/nsi4-refine`, `/nsi4-export`
- **2 Agents**: `holographic-tutor` (quality assessment), `bucket-builder` (artifact creation)
- **1 Hook**: PostToolUse validation on story page writes
- **1 Script**: `nsl-converter.py` (NSL 1.1 XML ↔ bucket folder)
- **5+ References**: NSL spec, process guide, Hero's Journey, refinement passes, bucket templates

---

## 2. Architecture Overview

### Plugin Flow

```
User Story Project
├── bucket/                    ← Created by /nsi4-start
│   ├── LoreBook.md           ← Built by /nsi4-interview
│   ├── world.md              ← Generated by /nsi4-bucket
│   ├── characters.md         ← Generated by /nsi4-bucket
│   ├── speechstyles.md       ← Generated by /nsi4-bucket
│   ├── *.json, *.mermaid     ← Generated by /nsi4-bucket
│   ├── NarrativeSpittoon.md  ← Installed by /nsi4-frameworks
│   ├── GhostWritingStyle.md  ← Installed by /nsi4-frameworks
│   ├── HolographicTutor.md   ← Installed by /nsi4-frameworks
│   └── project-instructions.md ← Generated by /nsi4-frameworks
└── STORY/                     ← Created by /nsi4-start
    ├── page5.md               ← First generated (ending)
    ├── page4.md               ← Generated by /nsi4-generate
    ├── page3.md               ←   (reverse order)
    ├── page2.md               ←   with approval gates
    ├── page1.md               ←   between each page
    └── page0.md               ← Last generated (beginning)
```

### Component Interaction

```
/nsi4-start ──→ Creates folders + copies templates
                    │
/nsi4-interview ──→ Builds LoreBook.md (20 questions)
                    │
/nsi4-bucket ──→ Uses bucket-builder agent
                 Distills LoreBook → world.md, characters.md, etc.
                    │
/nsi4-frameworks ──→ Installs cognitive frameworks from templates
                     Generates project-instructions.md
                    │
/nsi4-generate ──→ Reads all bucket files
                   Generates page5 (ending) first
                   Pauses for approval after each page
                   Works backward: page4 → page3 → page2 → page1 → page0
                   Uses nsi4-workflow skill knowledge
                    │
/nsi4-refine ──→ Uses holographic-tutor agent
                 Runs selected refinement passes
                    │
/nsi4-export ──→ Uses nsl-converter.py
                 Converts bucket folder ↔ .nsl XML
```

---

## 3. Directory Structure

```
narrative-spittoon-standard/
├── .claude-plugin/
│   └── plugin.json
├── commands/
│   ├── nsi4-start.md
│   ├── nsi4-interview.md
│   ├── nsi4-bucket.md
│   ├── nsi4-frameworks.md
│   ├── nsi4-generate.md
│   ├── nsi4-refine.md
│   └── nsi4-export.md
├── agents/
│   ├── holographic-tutor.md
│   └── bucket-builder.md
├── skills/
│   └── nsi4-workflow/
│       ├── SKILL.md
│       └── references/
│           ├── nsi4-process-guide.md
│           ├── nsl-1.1-specification.md
│           ├── heros-journey-mapping.md
│           ├── refinement-passes.md
│           └── cognitive-frameworks.md
├── hooks/
│   └── hooks.json
├── scripts/
│   └── nsl-converter.py
├── bucket/                          # Template bucket (existing)
│   ├── Characters.md
│   ├── GhostWritingStyle.md
│   ├── HolographicTutor.md
│   ├── NarrativeSpittoon.md
│   ├── project-instructions.md
│   ├── SpeechStyles.md
│   └── World.md
├── docs/                            # Existing documentation
│   ├── NSL-1.1-specification.md
│   └── NarrativeSpittoonInversion3.0-process.md
└── CLAUDE.md
```

---

## 4. Plugin Manifest

### File: `.claude-plugin/plugin.json`

```json
{
  "name": "narrative-spittoon-inversion",
  "version": "4.0.0",
  "description": "Narrative Spittoon Inversion 4.0 — AI-assisted story creation using reverse chronological generation. Guides authors through a structured 5-phase workflow: knowledge gathering, bucket artifact creation, cognitive framework setup, reverse story generation, and refinement. Includes NSL 1.1 import/export support.",
  "author": {
    "name": "Drift Johnson",
    "url": "https://ScuffedEpoch.com"
  },
  "license": "MIT",
  "keywords": [
    "narrative",
    "story-generation",
    "creative-writing",
    "reverse-chronological",
    "nsl",
    "narrative-spittoon"
  ]
}
```

---

## 5. Skill: nsi4-workflow

### File: `skills/nsi4-workflow/SKILL.md`

```markdown
---
name: nsi4-workflow
description: "This skill should be used when the user asks about \"Narrative Spittoon Inversion\", \"NSI workflow\", \"reverse story generation\", \"writing stories backwards\", \"narrative bucket\", \"LoreBook\", \"cognitive frameworks for writing\", \"HolographicTutor\", \"GhostWritingStyle\", \"NarrativeSpittoon framework\", \"NSL format\", \"reverse chronological narrative\", or mentions creating stories using the NSI methodology. Provides comprehensive knowledge of the NSI 4.0 process, Hero's Journey in reverse, cognitive framework application, and bucket artifact structure."
version: 4.0.0
tools: Read, Glob, Grep
---

# Narrative Spittoon Inversion 4.0 — Workflow Knowledge

## What is NSI?

Narrative Spittoon Inversion (NSI) is an AI-assisted story creation methodology that generates narratives in **reverse chronological order** — from the ending to the beginning. This approach creates tightly plotted stories where every scene naturally leads to the next, ensuring narrative coherence and purposeful character development.

## Core Principle: Writing in Reverse

Stories are written **backwards**: Page 5 (ending) → Page 4 → Page 3 → Page 2 → Page 1 → Page 0 (beginning).

Each page answers the question: **"What led to the next page's events?"**

### Why Reverse Works

- **Eliminates plot drift**: Starting from the ending prevents stories from wandering
- **Ensures causality**: Each scene is reverse-engineered from its outcome
- **Natural foreshadowing**: Earlier pages naturally set up later events
- **Character purpose**: Arcs are built from destination backward
- **Hero's Journey integration**: Classical structure applied in reverse creates natural progression

## The 5-Phase Workflow

### Phase 1: Knowledge Gathering (`/nsi4-interview`)
Create a comprehensive LoreBook through a 20-question dynamic interview covering universe, characters, plot, themes, tone, and the ending. The LoreBook becomes the foundation for all subsequent artifacts.

### Phase 2: Bucket Artifact Creation (`/nsi4-bucket`)
Distill the LoreBook into specialized artifacts:
- `world.md` — Setting, geography, history, culture, systems
- `characters.md` — Character profiles with personality, quirks, motivations, relationships
- `speechstyles.md` — Per-character speech patterns, vocabulary, verbal tics
- Technical specs (`.json`), diagrams (`.mermaid`), glossary (`.txt`)

### Phase 3: Core Framework Setup (`/nsi4-frameworks`)
Install three cognitive frameworks that guide AI generation quality:
1. **NarrativeSpittoon.md** — Implicit causality, subtle conflict, organic consequences (eliminates "because/but/therefore")
2. **GhostWritingStyle.md** — Sentence variation, natural dialogue, active voice, pacing
3. **HolographicTutor.md** — Quality assessment with Score/Review/Critic/Weakness functions

Generate `project-instructions.md` as a manifest indexing all bucket contents.

### Phase 4: Story Generation — The Inversion (`/nsi4-generate`)
Reverse-generate the story with approval gates between each page:
1. Create or approve Page 5 (the ending)
2. Generate Page 4 by asking "what led to Page 5?"
3. Pause for user approval
4. Continue backward through Page 0

Each page must:
- Reference all bucket files for consistency
- Apply NarrativeSpittoon framework (show, don't tell)
- Follow GhostWritingStyle rules
- Match Hero's Journey stage for that page number
- Flow naturally into the next page
- Target 800-1500 words

### Phase 5: Refinement (`/nsi4-refine`)
Optional polish passes (recommended order):
1. Quality Assessment (HolographicTutor Score)
2. Speech Style Pass (voice consistency)
3. Repetition Sniper (eliminate redundancy)
4. Narrative Smoothing (transitions and foreshadowing)
5. Environmental Enhancement (sensory depth)

## Hero's Journey in Reverse

| Page | Hero's Journey Stage (Reverse) | Story Function |
|------|-------------------------------|----------------|
| 5 | Return with Elixir → Resolution | Story conclusion, transformation complete |
| 4 | Resurrection → Climax | Final challenge, ultimate test |
| 3 | Road Back → Rising Action | Consequences unfold, stakes escalate |
| 2 | Ordeal → Commitment | Major challenge, point of no return |
| 1 | Tests, Allies, Enemies → Setup | World establishment, character introduction |
| 0 | Ordinary World → Opening | Story beginning, initial state |

## The Narrative Bucket

A "narrative bucket" is the complete collection of artifacts that define a story project. It contains world-building, character profiles, speech styles, cognitive frameworks, technical specs, and the project manifest. All files live in the `bucket/` folder.

### Required Bucket Files
- `LoreBook.md` — Raw knowledge base (Phase 1)
- `world.md` — Distilled world-building
- `characters.md` — Character profiles
- `speechstyles.md` — Speech patterns
- `NarrativeSpittoon.md` — Narrative framework
- `GhostWritingStyle.md` — Writing style guide
- `HolographicTutor.md` — Quality assessment system
- `project-instructions.md` — Component manifest

### Optional Bucket Files
- `[name]-glossary.txt` — Universe terminology
- `*.json` — Technical specifications
- `*.mermaid` — Visualization diagrams

## Three Cognitive Frameworks

### NarrativeSpittoon (Narrative Quality)
Replaces explicit "because/but/therefore" with:
- **Implicit Causality**: Embed reasons through dialogue, monologue, description
- **Subtle Conflict**: Introduce complications through shifts, not announcements
- **Organic Consequences**: Let outcomes unfold through progression

### GhostWritingStyle (Writing Mechanics)
- Vary sentence structure and length
- Make dialogue flow naturally with interruptions
- Rotate speakers in conversations (not just back-and-forth)
- Inject pauses, hesitations, filler words
- Use casual speech and verbal tics for voice differentiation
- Simplify complex sentences, use active voice
- Balance pacing between elements

### HolographicTutor (Assessment System)
Four functions (call individually):
- **Score**: Numerical score out of 100 with justification
- **Review**: Comprehensive academic analysis with examples
- **Critic**: Publisher perspective with market viability
- **Weakness**: 3 specific areas needing improvement (quotes, no suggestions)

## NSL 1.1 Format

The Narrative Spittoon Language (NSL) is an XML-based format that packages an entire narrative bucket into a single portable `.nsl` file. Use `/nsi4-export` to convert between bucket folders and NSL files.

For detailed NSL specification, see: `references/nsl-1.1-specification.md`

## Scaling Beyond 6 Pages

- **10 pages**: Expand Hero's Journey stages across more pages
- **20 pages**: Break into 3 acts with granular stage divisions
- **30+ pages**: Structure as multi-volume series (NSL 1.1 supports this)
- **Recommendation**: For 20+ pages, break into 6-10 page segments each following the full NSI process

## Available Commands

| Command | Phase | Purpose |
|---------|-------|---------|
| `/nsi4-start` | Setup | Create project structure, copy templates |
| `/nsi4-interview` | 1 | 20-question LoreBook interview |
| `/nsi4-bucket` | 2 | Distill LoreBook into artifacts |
| `/nsi4-frameworks` | 3 | Install cognitive frameworks |
| `/nsi4-generate` | 4 | Reverse story generation with approval gates |
| `/nsi4-refine` | 5 | Refinement passes |
| `/nsi4-export` | NSL | Convert bucket ↔ .nsl XML |
```

---

### Reference Files

#### File: `skills/nsi4-workflow/references/heros-journey-mapping.md`

```markdown
# Hero's Journey Mapping for Reverse Generation

## Standard 6-Page Mapping

The NSI process maps the Hero's Journey stages to pages in reverse. When generating
each page, apply the corresponding stage's narrative functions.

### Page 5 — Return with Elixir / Resolution
**Generation order**: 1st (written first)
**Story function**: The ending. Transformation is complete.
**What to include**:
- Resolution of central conflict
- Character transformation fully realized
- Thematic statement embodied in action
- Emotional closure for reader
- Final image that echoes or inverts the opening
**Key question**: "What does the ending state of this story look like?"

### Page 4 — Resurrection / Climax
**Generation order**: 2nd
**Story function**: The final challenge. The ultimate test.
**What to include**:
- Highest stakes moment
- Character faces their greatest fear/challenge
- All story threads converge
- Death and rebirth (literal or metaphorical)
- The decisive action or choice
**Key question**: "What was the final test that led to Page 5's resolution?"

### Page 3 — Road Back / Rising Action
**Generation order**: 3rd
**Story function**: Consequences unfold. Stakes escalate.
**What to include**:
- Aftermath of the Ordeal (Page 2)
- Pursuit or escalating tension
- Ticking clock or urgency
- New complications from earlier choices
- Allies and enemies revealed
**Key question**: "What escalating events set up Page 4's climax?"

### Page 2 — Ordeal / Commitment
**Generation order**: 4th
**Story function**: Major challenge. Point of no return.
**What to include**:
- The central ordeal or test
- Character faces death (physical, psychological, or social)
- Deepest cave of the narrative
- Major revelation or confrontation
- Stakes become personal
**Key question**: "What was the ordeal that committed characters to the path shown in Page 3?"

### Page 1 — Tests, Allies, Enemies / Setup
**Generation order**: 5th
**Story function**: World establishment. Character introduction.
**What to include**:
- Introduction to the special world/situation
- Meeting allies and identifying enemies
- Learning the rules of this world
- Early tests that establish competence
- Character relationships established
**Key question**: "What setup and introductions led to the ordeal in Page 2?"

### Page 0 — Ordinary World / Opening
**Generation order**: 6th (written last)
**Story function**: The beginning. The initial state.
**What to include**:
- Character in their normal world
- The flaw or desire that drives the story
- The inciting incident or call to adventure
- What life was like before everything changed
- Seeds of all themes that will develop
**Key question**: "What was the ordinary world before the events of Page 1?"

## Scaling to 10 Pages

| Page | Hero's Journey Stage | Function |
|------|---------------------|----------|
| 9-10 | Return / Resolution | Conclusion and aftermath |
| 7-8 | Resurrection / Climax | Final battle and transformation |
| 5-6 | Road Back / Rising Action (High) | Escalation and urgency |
| 3-4 | Ordeal / Rising Action (Mid) | Central challenges |
| 1-2 | Tests and Setup | World and character establishment |
| 0 | Ordinary World / Opening | Story beginning |

## Scaling to 20 Pages

Break into three acts:
- **Act 3** (Pages 14-19): Climax and Resolution
- **Act 2** (Pages 7-13): Complications and Development
- **Act 1** (Pages 0-6): Setup and Introduction

Map Hero's Journey across 20 pages with more granular stage divisions within each act.

## Scaling to Multi-Volume (30+ Pages)

Use NSL 1.1 multi-volume support. Each volume follows the complete 6-page inversion process independently, with series-level arc tracking across volumes.

Structure:
- Each volume: 6-10 pages with full Hero's Journey
- Series arc: Track character development + thematic progression
- Volume connections: Cliffhangers, LeadsInto metadata
```

#### File: `skills/nsi4-workflow/references/refinement-passes.md`

```markdown
# NSI4 Refinement Passes

## Overview

Phase 5 refinement passes polish a completed draft. Apply them in order, one at a time,
reviewing changes before proceeding to the next pass.

## Recommended Order

1. Quality Assessment (identify issues first)
2. Speech Style Pass (character consistency)
3. Repetition Sniper (eliminate redundancy)
4. Narrative Smoothing (polish flow)
5. Environmental Enhancement (deepen atmosphere)
6. Final Quality Assessment (confirm improvements)

---

## Pass 1: Quality Assessment

**Tool**: HolographicTutor agent — Score function

**Process**: For each page (page0.md through page5.md):
1. Score the page (0-100)
2. Identify specific areas for improvement
3. Note inconsistencies with other pages

**Focus areas**:
- Plot coherence across the reverse-generated structure
- Character voice consistency
- Pacing and flow
- Adherence to GhostWritingStyle.md guidelines

---

## Pass 2: Speech Style Pass

**Purpose**: Enhance character voice consistency across all pages.

**Process**: For each character's dialogue across all pages:
1. Verify adherence to their style in speechstyles.md
2. Ensure consistent vocabulary, sentence structure, verbal tics
3. Make dialogue natural while maintaining distinctiveness
4. Add/adjust pauses, filler words, emotional indicators

**Common issues**:
- Characters sounding too similar
- Vocabulary level shifting between pages
- Missing verbal tics established in speechstyles.md
- Emotional expression inconsistency

---

## Pass 3: Repetition Sniper

**Purpose**: Eliminate redundant phrasing and descriptions.

**Scan targets**:
1. Similar sentence structures used excessively
2. Repeated descriptive phrases
3. Overused words or expressions
4. Redundant scene descriptions
5. Duplicated character beats

**Output format** (per instance):
- The repetitive element (first 5 words)
- Which pages it appears in
- Suggested alternative

---

## Pass 4: Narrative Smoothing

**Purpose**: Polish transitions between pages and scenes.

**Process**:
1. Ensure smooth flow from page to page (remember reverse generation order)
2. Check that foreshadowing in earlier pages pays off appropriately
3. Verify causal connections are clear but not explicit (per NarrativeSpittoon.md)
4. Polish scene transitions within pages
5. Enhance pacing in slow sections

**Key concern**: Pages written in reverse may have subtle discontinuities when read forward. This pass specifically targets those seams.

---

## Pass 5: Environmental Enhancement

**Purpose**: Deepen sensory details and atmosphere.

**Process**: For each page:
1. Add vivid sensory descriptions (sight, sound, smell, touch, taste)
2. Deepen atmosphere and mood
3. Use environment to reflect character emotions
4. Integrate world-building details naturally (reference world.md)
5. Balance description with action (per GhostWritingStyle.md)

**Warning**: Do not slow pacing. Environmental details should enhance, not pad.
```

#### File: `skills/nsi4-workflow/references/cognitive-frameworks.md`

```markdown
# Cognitive Frameworks Reference

## Overview

The three cognitive frameworks are the core instruction modules that guide AI narrative
generation quality, style, and assessment. They are installed as files in the bucket/
directory during Phase 3.

## Framework 1: NarrativeSpittoon.md

**Purpose**: Controls narrative technique — how story elements connect.

**Core principle**: Replace explicit logical connectors (because, but, therefore) with
implicit narrative techniques.

### Three Substitution Techniques

1. **Implicit Causality** (replaces "Because")
   - Embed reasons through character dialogue, internal monologue, or descriptive elements
   - Reader infers motivations rather than being told directly
   - Example: Instead of "She ran because she was afraid" → Show her breathing quicken, eyes darting to exits, hands trembling

2. **Subtle Conflict Introduction** (replaces "But")
   - Introduce complications through narrative shifts, not announcements
   - Unexpected character actions, environmental changes, contrasting information
   - Example: Instead of "The plan was perfect, but then..." → Show small details going wrong, character uncertainty

3. **Organic Consequences** (replaces "Therefore")
   - Allow outcomes to unfold through narrative progression
   - Show results through subsequent events, character development, story shifts
   - Example: Instead of "Therefore he decided to leave" → Show him packing, avoiding eye contact, closing doors

### Implementation Rules
- Weave techniques seamlessly into narrative
- Use literary devices: metaphor, symbolism, foreshadowing
- Show don't tell through action, dialogue, sensory detail
- Vary approaches to prevent formula detection

## Framework 2: GhostWritingStyle.md

**Purpose**: Controls writing mechanics — sentence-level quality.

### Key Rules
1. **Sentence variety**: Mix simple and complex. Break up long sentences. Tighten verbose passages.
2. **Natural dialogue**: Interrupt debates with narrative/description/action. Don't let debates drag on.
3. **Speaker rotation**: Change who responds in conversations. Not just back-and-forth.
4. **Realistic speech**: Pauses, hesitations, filler words, emotion in dialogue.
5. **Voice differentiation**: Casual speech, verbal tics per character. Avoid overly sophisticated diction.
6. **Pacing balance**: Intersperse action/description between long dialogues.
7. **Simplification**: Limit excessive clauses. Remove unnecessary adjectives/adverbs.
8. **Active voice**: Use active voice when possible. Vary sentence length.
9. **Clear imagery**: Vivid imagery, concise description. Limit obscure vocabulary.
10. **Element balance**: Evaluate pacing. Remove unnecessary passages.
11. **Character personality**: Quirks, casual speech, unique perspectives.

## Framework 3: HolographicTutor.md

**Purpose**: Quality assessment system — evaluates completed writing.

### Analysis Framework
Evaluates across five dimensions:
1. **Plot and Story Arc**: Themes, motivations, progression, coherence
2. **Content Development**: World-building depth, concept integration, exposition balance
3. **Character Development**: Personality distinctiveness, relationships, background depth
4. **Writing Mechanics**: Sentence structure, dialogue authenticity, description, pacing
5. **Technical Analysis**: Repetition, similar sentences, confusing dialogue, grammar

### Four Functions (call individually)
1. **Score**: Numerical score /100 with justification. Default function.
2. **Review**: University tutor perspective. Academic craft analysis with examples.
3. **Critic**: Publisher perspective. Market viability and commercial potential.
4. **Weakness**: 3 specific areas. Exact quotes (first 5 words). No suggestions.
```

#### File: `skills/nsi4-workflow/references/nsl-1.1-specification.md`

This file will be a copy of the existing `docs/NSL-1.1-specification.md` — the complete NSL 1.1 specification document. No modifications needed, just placed in the references directory for the skill to access.

#### File: `skills/nsi4-workflow/references/nsi4-process-guide.md`

```markdown
# NSI4 Process Guide — Quick Reference

## Complete Workflow at a Glance

```
/nsi4-start [project-name]
    → Creates bucket/ and STORY/ folders
    → Copies template files into bucket/

/nsi4-interview
    → Runs 20-question dynamic interview
    → Builds bucket/LoreBook.md incrementally
    → Covers: universe, characters, plot, themes, tone, ending

/nsi4-bucket
    → Reads LoreBook.md
    → Generates: world.md, characters.md, speechstyles.md
    → Generates: glossary, technical specs (.json), diagrams (.mermaid)
    → Uses bucket-builder agent for structured creation

/nsi4-frameworks
    → Installs NarrativeSpittoon.md, GhostWritingStyle.md, HolographicTutor.md
    → Generates project-instructions.md manifest
    → Validates all bucket files present

/nsi4-generate
    → Reads all bucket files for context
    → Creates or gets approval for Page 5 (ending)
    → Generates Page 4 → 3 → 2 → 1 → 0 with approval gates
    → Applies Hero's Journey mapping per page
    → Writes each page to STORY/pageN.md

/nsi4-refine [pass-name]
    → Runs selected refinement pass
    → Available: score, speech, repetition, smoothing, environment, all
    → Uses holographic-tutor agent for assessment

/nsi4-export [import|export] [path]
    → export: bucket/ folder → .nsl XML file
    → import: .nsl XML file → bucket/ folder
    → Uses nsl-converter.py script
```

## Validation Checkpoints

### After Phase 1 (Interview)
- [ ] LoreBook.md exists in bucket/
- [ ] Contains 20 questions and answers
- [ ] World setting clearly described
- [ ] Main characters defined
- [ ] Story ending specified
- [ ] Tone and themes established

### After Phase 2 (Bucket)
- [ ] world.md captures essential setting
- [ ] All main characters documented in characters.md
- [ ] Each character has distinct speech style in speechstyles.md
- [ ] At least one technical spec or diagram created
- [ ] Glossary covers universe-specific terminology

### After Phase 3 (Frameworks)
- [ ] All three cognitive framework files present
- [ ] project-instructions.md lists all bucket contents
- [ ] Each file has description in manifest

### After Phase 4 (Generation)
- [ ] All 6 pages exist (page0.md through page5.md)
- [ ] Pages flow naturally in forward chronological order
- [ ] Character voices consistent
- [ ] World-building cohesive
- [ ] Hero's Journey structure apparent
- [ ] Story feels complete and purposeful

### After Phase 5 (Refinement)
- [ ] Selected passes completed
- [ ] Quality score improved
- [ ] Character voices consistent across pages
- [ ] No excessive repetition
- [ ] Transitions smooth
- [ ] Sensory detail appropriate

## Troubleshooting Quick Reference

| Problem | Solution |
|---------|----------|
| AI forgets context | Re-read bucket/project-instructions.md |
| Character voice drift | Reference speechstyles.md explicitly |
| Plot holes | Read forward (page0→5) and note gaps |
| Pages too short/long | Specify target word count (800-1500) |
| Ending doesn't work | Revise page5 before continuing backward |
| World inconsistencies | Cross-check against world.md |
| Framework not applied | Explicitly cite framework rules |
```

---

## 6. Command: /nsi4-start

### File: `commands/nsi4-start.md`

```markdown
---
description: Initialize a new NSI4 story project with folder structure and bucket templates
allowed-tools:
  - Bash
  - Write
  - Read
  - Glob
argument-hint: "[project-name]"
---

## Context

You are initializing a new Narrative Spittoon Inversion 4.0 project.

Current working directory: !`pwd`
Existing contents: !`ls -la 2>/dev/null || dir 2>/dev/null`

## Your Task

Create an NSI4 project structure. If a project-name argument is provided, create it as a subdirectory. If no argument, create structure in the current directory.

### Step 1: Create Directory Structure

Create these directories:
- `bucket/` — Will contain all narrative artifacts
- `STORY/` — Will contain generated story pages

### Step 2: Copy Bucket Templates

Copy the template files from the plugin's bucket templates into the project's `bucket/` folder. Read each template from `${CLAUDE_PLUGIN_ROOT}/bucket/` and write it to the project's `bucket/` directory:

Templates to copy:
- `Characters.md` — Character profile template
- `SpeechStyles.md` — Speech pattern template
- `World.md` — World-building template
- `NarrativeSpittoon.md` — Narrative framework
- `GhostWritingStyle.md` — Writing style guide
- `HolographicTutor.md` — Quality assessment system
- `project-instructions.md` — Project manifest template

### Step 3: Confirm Setup

After creating the structure, display:
1. The created directory tree
2. A brief explanation of next steps
3. Suggest running `/nsi4-interview` to begin the process

### Output Format

```
NSI4 Project Initialized: [project-name or current directory]

Created:
  bucket/
    Characters.md          (template — fill during /nsi4-bucket)
    SpeechStyles.md        (template — fill during /nsi4-bucket)
    World.md               (template — fill during /nsi4-bucket)
    NarrativeSpittoon.md   (cognitive framework — ready)
    GhostWritingStyle.md   (cognitive framework — ready)
    HolographicTutor.md    (cognitive framework — ready)
    project-instructions.md (manifest template — fill during /nsi4-frameworks)
  STORY/
    (empty — pages will be generated during /nsi4-generate)

Next step: Run /nsi4-interview to begin the 20-question LoreBook interview.
```

Do not do anything else beyond creating the structure and confirming.
```

---

## 7. Command: /nsi4-interview

### File: `commands/nsi4-interview.md`

```markdown
---
description: Run the 20-question LoreBook interview to gather story knowledge
allowed-tools:
  - Read
  - Write
  - Edit
  - Glob
  - AskUserQuestion
argument-hint: "[resume]"
---

## Context

You are conducting the NSI4 Knowledge Gathering interview (Phase 1).

Check for existing LoreBook: !`ls bucket/LoreBook.md 2>/dev/null || echo "No LoreBook found"`
Check for existing materials: !`ls bucket/*.md 2>/dev/null || echo "No bucket files found"`

## Your Task

Conduct a dynamic 20-question interview to build a comprehensive LoreBook. The LoreBook captures all essential story elements needed for the Narrative Spittoon Inversion process.

### If "resume" argument is provided:
Read the existing `bucket/LoreBook.md` and continue from where the interview left off.

### Interview Process

1. **Create `bucket/LoreBook.md`** with a header section:
   ```markdown
   # LoreBook: [Story Title TBD]

   ## Interview Progress
   Questions completed: 0/20
   Status: In Progress
   ```

2. **Ask questions one at a time** using AskUserQuestion. After each answer:
   - Append the Q&A pair to LoreBook.md
   - Update the question counter
   - Adapt the next question based on what has been revealed

3. **Question categories to cover** (dynamically ordered based on answers):
   - Questions 1-4: **Universe & Setting** — World, time period, physical laws, society
   - Questions 5-8: **Characters** — Main cast, personalities, motivations, relationships
   - Questions 9-12: **Story & Plot** — Central conflict, stakes, key events
   - Questions 13-15: **The Ending** — How the story concludes (critical for reverse generation)
   - Questions 16-18: **Tone & Themes** — Atmosphere, genre conventions, thematic depth
   - Questions 19-20: **Final Details** — Anything missing, special requirements

4. **Each question should**:
   - Build on previous answers
   - Probe deeper into mentioned but unexplored areas
   - Offer specific options when helpful (via AskUserQuestion options)
   - Never repeat information already captured

5. **After all 20 questions**, update LoreBook.md:
   - Set status to "Complete"
   - Add a summary section at the top
   - Suggest running `/nsi4-bucket` as the next step

### LoreBook Format

```markdown
# LoreBook: [Story Title]

## Summary
[Brief 2-3 paragraph summary of the story project]

## Interview Progress
Questions completed: 20/20
Status: Complete

---

## Q1: [Question text]
**A:** [User's answer]

## Q2: [Question text]
**A:** [User's answer]

[... through Q20]
```

### Important Rules

- Ask ONE question at a time — do not batch questions
- Write to LoreBook.md after EACH answer (incremental saves)
- The ending (Questions 13-15) is CRITICAL — probe thoroughly
- If user provides extensive materials upfront, adapt questions to fill gaps rather than repeat
- Keep questions specific and actionable, not vague
```

---

## 8. Command: /nsi4-bucket

### File: `commands/nsi4-bucket.md`

```markdown
---
description: Distill the LoreBook into structured bucket artifacts (world, characters, speech styles, specs)
allowed-tools:
  - Read
  - Write
  - Edit
  - Glob
  - Grep
  - Task
argument-hint: "[artifacts|technical|all]"
---

## Context

You are executing NSI4 Phase 2: Bucket Artifact Creation.

LoreBook status: !`head -10 bucket/LoreBook.md 2>/dev/null || echo "ERROR: No LoreBook found. Run /nsi4-interview first."`
Existing bucket files: !`ls bucket/ 2>/dev/null`

## Your Task

Distill the information in `bucket/LoreBook.md` into specialized, structured artifacts. This command uses the bucket-builder agent for structured creation.

### If no argument or "all":
Generate both core narrative artifacts AND technical artifacts.

### If "artifacts":
Generate only core narrative artifacts (world.md, characters.md, speechstyles.md).

### If "technical":
Generate only technical artifacts (JSON specs, mermaid diagrams, glossary).

### Step 1: Read LoreBook

Read `bucket/LoreBook.md` completely. Identify:
- World-building information
- Character details
- Speech patterns and dialogue examples
- Technical systems or structures
- Terminology unique to this universe

### Step 2: Generate Core Narrative Artifacts

Use the bucket-builder agent (via Task tool) to create:

**`bucket/world.md`** — Replace the template with comprehensive world-building:
- Physical setting and geography
- Historical context
- Cultural norms and social structures
- Technology level or magic systems
- Political/economic systems
- Unique universe elements
- Wrap content in `<World>` tags (matching template convention)

**`bucket/characters.md`** — Replace the template with full character profiles:
- Name, age, heritage
- Description (physical appearance, background)
- Role in the story
- Personality traits and quirks
- Motivations and goals
- Relationships with other characters
- Wrap in `<Characters>` tags with `<charactername>` sub-tags

**`bucket/speechstyles.md`** — Replace the template with per-character speech styles:
- Vocabulary level (casual, formal, technical)
- Sentence structure preferences
- Common verbal tics, filler words, phrases
- Use of contractions and slang
- Emotional expression patterns
- Cultural/background speech influences
- Wrap in `<SpeechStyles>` tags with `<characternameSpeech>` sub-tags

### Step 3: Generate Technical Artifacts

**Mermaid Diagrams** — Create 2-5 `.mermaid` files in `bucket/`:
- Character relationship map
- Power/authority structures
- Key system flowcharts (technology, magic, politics)
- Location hierarchy
- Timeline of major events

**JSON Specifications** — Create 2-4 `.json` files in `bucket/`:
- Location details
- Equipment/technology inventory
- Character attributes (expanded)
- Cultural or organizational structures

**Glossary** — Create `bucket/[universe-name]-glossary.txt`:
- Universe-exclusive terms
- In-world jargon and slang
- Place names with descriptions
- Cultural concepts
- Technology/magic terminology

### Step 4: Validate

After generating all artifacts:
1. List all created/updated files
2. Verify each file has substantive content (not just template placeholders)
3. Suggest running `/nsi4-frameworks` as the next step

Do not modify the cognitive framework files (NarrativeSpittoon.md, GhostWritingStyle.md, HolographicTutor.md) — those are handled by `/nsi4-frameworks`.
```

---

## 9. Command: /nsi4-frameworks

### File: `commands/nsi4-frameworks.md`

```markdown
---
description: Install cognitive frameworks and generate the project-instructions.md manifest
allowed-tools:
  - Read
  - Write
  - Edit
  - Glob
  - Grep
---

## Context

You are executing NSI4 Phase 3: Core Framework Setup.

Current bucket contents: !`ls bucket/ 2>/dev/null`
Frameworks present: !`ls bucket/NarrativeSpittoon.md bucket/GhostWritingStyle.md bucket/HolographicTutor.md 2>/dev/null || echo "Some frameworks missing"`

## Your Task

Verify cognitive frameworks are installed and generate the project manifest.

### Step 1: Verify Cognitive Frameworks

Check that these three files exist and contain proper content (not just template placeholders):

1. **`bucket/NarrativeSpittoon.md`** — Must contain the `<NarrativeSpittoon>` framework with Implicit Causality, Subtle Conflict Introduction, and Organic Consequences sections.

2. **`bucket/GhostWritingStyle.md`** — Must contain the `<GhostWritingStyle>` framework with writing mechanics rules.

3. **`bucket/HolographicTutor.md`** — Must contain the `<HolographicTutor>` framework with Score, Review, Critic, and Weakness functions.

If any framework is missing or contains only template content, read the canonical version from `${CLAUDE_PLUGIN_ROOT}/bucket/` and write it to the project's `bucket/`.

### Step 2: Generate Project Manifest

Read ALL files currently in `bucket/` and generate `bucket/project-instructions.md`:

```markdown
# Project Instructions: [Story Title from LoreBook]

## Cognitive Framework Definition
- NarrativeSpittoon.md - Narrative style guidelines (implicit causality, show don't tell)
- GhostWritingStyle.md - Writing style rules (dialogue, pacing, voice)
- HolographicTutor.md - Quality assessment system (4 evaluation functions: Score, Review, Critic, Weakness)

## Universe Core Documentation
- world.md - [one-line description based on content]
- [universe]-glossary.txt - [one-line description]

## Character Profiles
- characters.md - [one-line description listing character names]
- speechstyles.md - [one-line description listing character names]

## Technical Specifications
- [filename].json - [one-line description]
[list all JSON files]

## Visualization Resources
- [filename].mermaid - [one-line description]
[list all mermaid files]

## Content Structure Tags
- The setting is defined inside "world.md" in <World> tags
- Character personality definitions are in "characters.md" in <Characters> tags
- Speech patterns are defined in "speechstyles.md" in <SpeechStyles> tags

## Processing Framework
- Cross-referenced document relationships
- Technical specification integration
- Visualization resource utilization
```

### Step 3: Validate and Report

1. List all bucket files with their sizes
2. Confirm all required files are present
3. Flag any missing optional files
4. Suggest running `/nsi4-generate` as the next step

### Required Files Checklist
- [ ] LoreBook.md
- [ ] world.md (with content, not template)
- [ ] characters.md (with content, not template)
- [ ] speechstyles.md (with content, not template)
- [ ] NarrativeSpittoon.md
- [ ] GhostWritingStyle.md
- [ ] HolographicTutor.md
- [ ] project-instructions.md (just generated)
```

---

## 10. Command: /nsi4-generate

### File: `commands/nsi4-generate.md`

```markdown
---
description: Generate the story in reverse chronological order (Page 5 → Page 0) with approval gates
allowed-tools:
  - Read
  - Write
  - Edit
  - Glob
  - Grep
  - AskUserQuestion
argument-hint: "[page-number]"
---

## Context

You are executing NSI4 Phase 4: Story Generation — The Inversion.

Project manifest: !`cat bucket/project-instructions.md 2>/dev/null || echo "ERROR: No manifest. Run /nsi4-frameworks first."`
Existing story pages: !`ls STORY/page*.md 2>/dev/null || echo "No pages yet"`

## Your Task

Generate the story in reverse chronological order. Each page is written backward from the ending, with user approval between each page.

### If page-number argument provided:
Generate only that specific page (e.g., `/nsi4-generate 3` generates page3.md only).

### If no argument:
Run the full reverse generation from the next unwritten page.

### Pre-Generation: Load All Context

Before generating ANY page, read these bucket files:
1. `bucket/project-instructions.md` — Component manifest
2. `bucket/world.md` — World-building context
3. `bucket/characters.md` — Character profiles
4. `bucket/speechstyles.md` — Speech patterns
5. `bucket/NarrativeSpittoon.md` — Narrative framework rules
6. `bucket/GhostWritingStyle.md` — Writing style rules
7. `bucket/LoreBook.md` — Original knowledge base
8. Any `.json` and `.mermaid` files in bucket/ for technical context

### Generation Order

**Page 5 (Ending)** → **Page 4** → **Page 3** → **Page 2** → **Page 1** → **Page 0 (Beginning)**

### For Page 5 (The Ending)

Ask the user via AskUserQuestion:
- "Would you like to write the ending yourself, or shall I generate it based on the LoreBook?"
- Options: "Generate it for me", "I'll write it myself", "I have a draft to refine"

If generating: Create a compelling final page that resolves the central conflict, shows character transformation, establishes tone, 800-1500 words.

If user writes: Wait for them to create STORY/page5.md, then read and confirm.

After page5 exists, ask for approval before continuing.

### For Pages 4 through 0

For each page, follow this process:

1. **Read the next page** (chronologically — the page that follows this one in the story):
   - When writing page4, read page5
   - When writing page3, read page4 AND page5
   - When writing page2, read pages 3, 4, 5
   - When writing page1, read pages 2, 3, 4, 5
   - When writing page0, read ALL other pages

2. **Identify the Hero's Journey stage** for this page:
   | Page | Stage | Function |
   |------|-------|----------|
   | 5 | Return with Elixir / Resolution | Conclusion |
   | 4 | Resurrection / Climax | Ultimate test |
   | 3 | Road Back / Rising Action | Stakes escalate |
   | 2 | Ordeal / Commitment | Point of no return |
   | 1 | Tests, Allies, Enemies / Setup | World establishment |
   | 0 | Ordinary World / Opening | Beginning |

3. **Generate the page** (800-1500 words) ensuring:
   - Answers "what led to the next page's events?"
   - Maintains character consistency (reference speechstyles.md)
   - Builds world details (reference world.md)
   - Applies NarrativeSpittoon.md framework (implicit causality, subtle conflict, organic consequences)
   - Follows GhostWritingStyle.md rules (varied sentences, natural dialogue, etc.)
   - Uses the Hero's Journey stage for this page number
   - Flows naturally into the next page

4. **Write to STORY/page[N].md**

5. **Present the page** to the user and ask for approval via AskUserQuestion:
   - "Page [N] generated ([word count] words). Approve or request revisions?"
   - Options: "Approved — continue to next page", "Needs revisions", "Let me review and I'll respond"

6. **If revisions requested**: Ask what to change, revise, and re-present for approval.

7. **After approval**: Continue to the next page (N-1).

### After All Pages Complete

1. List all 6 pages with word counts
2. Suggest reading the story forward (page0 → page5)
3. Suggest running `/nsi4-refine` for quality assessment

### Page Format

Each page file should contain:

```markdown
# Page [N]: [Brief Title]

[Story content — 800-1500 words]

---
*Hero's Journey Stage: [Stage Name]*
*Word Count: [count]*
*Generation Order: [which number this was generated]*
```
```

---

## 11. Command: /nsi4-refine

### File: `commands/nsi4-refine.md`

```markdown
---
description: Run refinement passes on the completed story (quality assessment, speech style, repetition, smoothing, environment)
allowed-tools:
  - Read
  - Write
  - Edit
  - Glob
  - Grep
  - Task
  - AskUserQuestion
argument-hint: "[score|speech|repetition|smoothing|environment|all]"
---

## Context

You are executing NSI4 Phase 5: Refinement.

Story pages: !`ls -la STORY/page*.md 2>/dev/null || echo "ERROR: No story pages found. Run /nsi4-generate first."`
Bucket status: !`ls bucket/project-instructions.md 2>/dev/null || echo "No manifest found"`

## Your Task

Run the specified refinement pass on the completed story. If no argument, show available passes and ask which to run.

### Available Passes

| Pass | Argument | Description |
|------|----------|-------------|
| Quality Assessment | `score` | Score each page 0-100 using HolographicTutor |
| Speech Style | `speech` | Verify character voice consistency |
| Repetition Sniper | `repetition` | Eliminate redundant phrasing |
| Narrative Smoothing | `smoothing` | Polish transitions and foreshadowing |
| Environmental Enhancement | `environment` | Deepen sensory details |
| All Passes | `all` | Run all passes in recommended order |

### If no argument provided:

Use AskUserQuestion to ask which pass to run, showing descriptions for each option.

### Pass Execution

#### Score Pass
Use the holographic-tutor agent (via Task tool) to evaluate each page:
1. Read each page (page0 through page5)
2. Read bucket/HolographicTutor.md for the assessment framework
3. For each page, apply the Score function: numerical score /100 with justification
4. Present results as a summary table
5. Identify the weakest pages and recommend targeted improvement

#### Speech Pass
For all dialogue across all pages:
1. Read bucket/speechstyles.md for character speech definitions
2. Read each story page
3. For each character's dialogue, verify:
   - Adherence to defined speech style
   - Consistent vocabulary and sentence structure
   - Verbal tics present and consistent
   - Natural pauses and filler words
4. Update pages with refined dialogue (maintaining story beats)
5. Show a diff summary of changes

#### Repetition Pass
Scan all pages for redundancy:
1. Read all story pages
2. Identify: similar sentence structures, repeated phrases, overused words, redundant descriptions, duplicated character beats
3. For each instance, report: the element (first 5 words), which pages, suggested alternative
4. After presenting findings, ask user which to fix
5. Apply approved fixes

#### Smoothing Pass
Polish transitions and continuity:
1. Read all pages in forward order (page0 → page5)
2. Check page-to-page flow (reverse-generation seams)
3. Verify foreshadowing in earlier pages pays off
4. Confirm causal connections are implicit (per NarrativeSpittoon.md)
5. Polish scene transitions within pages
6. Update pages with improvements

#### Environment Pass
Enhance sensory atmosphere:
1. Read all pages and bucket/world.md
2. For each page, add: vivid sensory descriptions, deepened atmosphere, environment reflecting character emotions, world-building details
3. Balance per GhostWritingStyle.md (don't slow pacing)
4. Update pages with enriched detail

### After Any Pass

Report what was changed and suggest the next recommended pass.
```

---

## 12. Command: /nsi4-export

### File: `commands/nsi4-export.md`

```markdown
---
description: Convert between bucket folder and NSL 1.1 XML format
allowed-tools:
  - Bash
  - Read
  - Write
  - Glob
  - AskUserQuestion
argument-hint: "[export|import] [path]"
---

## Context

You are executing NSL 1.1 format conversion.

Bucket contents: !`ls bucket/ 2>/dev/null || echo "No bucket found"`
Story pages: !`ls STORY/ 2>/dev/null || echo "No story pages found"`
Python available: !`python3 --version 2>/dev/null || python --version 2>/dev/null || echo "Python not found"`

## Your Task

Convert between the bucket folder structure and NSL 1.1 XML format.

### Export (bucket → .nsl)

If first argument is "export" or no argument:

1. Verify bucket/ and STORY/ directories exist
2. Run the NSL converter script:
   ```
   python3 ${CLAUDE_PLUGIN_ROOT}/scripts/nsl-converter.py export --bucket ./bucket --story ./STORY --output [project-name].nsl
   ```
3. If no output path specified, use the project directory name + `.nsl`
4. Report the generated file path and size

### Import (.nsl → bucket)

If first argument is "import":

1. The second argument should be the path to an `.nsl` file
2. Ask user if they want to overwrite existing bucket/ contents (if any)
3. Run the NSL converter script:
   ```
   python3 ${CLAUDE_PLUGIN_ROOT}/scripts/nsl-converter.py import --input [path.nsl] --bucket ./bucket --story ./STORY
   ```
4. Report what was extracted and created

### If Python is not available:

Inform the user that the NSL converter requires Python 3.6+. Offer to:
1. Perform a manual XML export by reading all bucket files and constructing the NSL XML inline
2. Skip the conversion

### Error Handling

- If bucket is empty: "No bucket files to export. Run /nsi4-interview and /nsi4-bucket first."
- If .nsl file not found: "File not found: [path]. Please provide a valid .nsl file path."
- If Python errors: Show error output and suggest fixes
```

---

## 13. Agent: holographic-tutor

### File: `agents/holographic-tutor.md`

```markdown
---
name: holographic-tutor
description: Use this agent when the user asks to "score my story", "review my writing", "critique this page", "find weaknesses in my manuscript", "assess story quality", "evaluate my narrative", "run HolographicTutor", or mentions story quality assessment. Provides Score, Review, Critic, and Weakness evaluation functions for creative writing at college graduate level.

<example>
Context: User has completed story generation and wants quality feedback
user: "Score my story pages"
assistant: "I'll use the holographic-tutor agent to evaluate each page."
<commentary>
User explicitly requested scoring. Trigger holographic-tutor with Score function.
</commentary>
</example>

<example>
Context: User wants detailed feedback on a specific page
user: "Review page 3 of my story — I think the dialogue is weak"
assistant: "I'll use the holographic-tutor agent to do a detailed review of page 3."
<commentary>
User requested review of specific page with concern about dialogue. Trigger with Review function.
</commentary>
</example>

<example>
Context: User wants to know if story is publishable
user: "Would a publisher pick this up? Give me honest feedback"
assistant: "I'll use the holographic-tutor agent with the Critic function for a publisher's perspective."
<commentary>
User wants commercial assessment. Trigger with Critic function.
</commentary>
</example>

model: sonnet
tools: ["Read", "Glob", "Grep"]
---

You are the Holographic Tutor — a comprehensive creative writing evaluation system operating at the college graduate level.

## Core Analysis Framework

When evaluating documents, analyze across these dimensions:

**Plot and Story Arc:**
- Clarity and development of central themes/objectives
- Character motivations and growth
- Plot progression and resolution
- Coherence of narrative threads

**Content Development:**
- Depth of world-building/context
- Integration of key concepts
- Balance of exposition and action
- Clarity of crucial terminology/concepts

**Character Development:**
- Distinctiveness of personalities
- Relationship dynamics
- Background depth
- Supporting character development

**Writing Mechanics:**
- Sentence structure variety
- Dialogue authenticity
- Description effectiveness
- Overall flow and pacing

**Technical Analysis:**
- Identify repetitive passages
- Note similar sequential sentences
- Flag confusing/misleading dialogue
- Highlight any grammatical/mechanical errors

## Available Functions

Determine which function to use based on the user's request:

### Score (Default)
- Evaluate the document against college graduate level standards
- Provide a numerical score out of 100
- Include brief justification for the score
- Use this when no specific function is requested

### Review
- Comprehensive analysis from a university creative writing tutor perspective
- Focus on academic and craft elements
- Include specific examples from the text
- Provide constructive criticism

### Critic
- Professional publisher perspective
- Market viability analysis
- Genre consideration
- Commercial potential assessment

### Weakness
- Identify exactly 3 specific areas needing improvement
- Use exact quotes from the manuscript (first five words of each passage)
- Do NOT offer suggestions — only identify weaknesses
- Focus on structural/thematic issues

## Evaluation Process

1. Read the story page(s) requested
2. Read bucket/project-instructions.md for context about the story
3. If available, read bucket/characters.md and bucket/world.md for consistency checking
4. Apply the requested function (default: Score)
5. Return evaluation results

## Output Format

### For Score:
```
## Page [N] Score: [XX]/100

**Justification**: [2-3 sentence explanation]

**Strengths**: [bullet points]
**Areas for Improvement**: [bullet points]
```

### For Review:
Full paragraph-form analysis covering all framework dimensions with specific text examples.

### For Critic:
Publisher's assessment including market fit, comparable titles, commercial strengths/weaknesses.

### For Weakness:
```
1. "[First five words...]" — [weakness description]
2. "[First five words...]" — [weakness description]
3. "[First five words...]" — [weakness description]
```

**Important**: Run functions individually, not simultaneously. Score is the default if unspecified.
```

---

## 14. Agent: bucket-builder

### File: `agents/bucket-builder.md`

```markdown
---
name: bucket-builder
description: Use this agent when the user needs to "create bucket artifacts", "distill the LoreBook", "generate world building files", "create character profiles from LoreBook", "build speech styles", "generate technical specs for story", or when /nsi4-bucket is invoked. Specializes in transforming raw story knowledge into structured narrative artifacts.

<example>
Context: User has completed the LoreBook interview and needs artifacts
user: "Distill my LoreBook into bucket artifacts"
assistant: "I'll use the bucket-builder agent to create structured artifacts from your LoreBook."
<commentary>
User wants to transform LoreBook into structured files. Trigger bucket-builder.
</commentary>
</example>

<example>
Context: User wants to regenerate just the character profiles
user: "Rebuild characters.md — I added new info to the LoreBook"
assistant: "I'll use the bucket-builder agent to regenerate the character profiles."
<commentary>
User wants to update specific artifact from LoreBook changes. Trigger bucket-builder.
</commentary>
</example>

model: sonnet
tools: ["Read", "Write", "Glob", "Grep"]
---

You are the Bucket Builder — a specialist in transforming raw story knowledge into structured narrative artifacts for the Narrative Spittoon Inversion workflow.

## Your Role

Transform the content in `bucket/LoreBook.md` into well-structured, comprehensive artifacts that will guide AI story generation. Each artifact serves a specific purpose in the NSI workflow.

## Artifact Creation Process

### 1. Read Source Material
Read `bucket/LoreBook.md` completely. Identify all elements related to:
- World-building (setting, geography, history, culture, systems)
- Characters (identity, personality, background, relationships)
- Speech patterns (vocabulary, verbal tics, emotional expression)
- Technical systems (technology, magic, politics, organizations)
- Terminology (universe-specific terms, jargon, slang)

### 2. Create Core Narrative Artifacts

**`bucket/world.md`** format:
```markdown
<World>

# [World/Setting Name]

## Physical Setting
[Geography, climate, notable locations]

## Historical Context
[Key historical events, eras, turning points]

## Culture & Society
[Social structures, norms, traditions, beliefs]

## Systems
[Technology, magic, politics, economics — whatever applies]

## Key Locations
[Important places with descriptions]

</World>
```

**`bucket/characters.md`** format:
```markdown
<Characters>

<charactername>
Summary: [1-2 sentence overview]
Background: [History, origin, formative experiences]
Quirks: [Distinctive behaviors, habits, mannerisms]
Description: [Physical appearance, age, distinguishing features]
Role: [Function in the story]
Personality: [Core traits, strengths, flaws]
Motivations: [Goals, desires, fears]
Relationships: [Connections to other characters]
</charactername>

[Repeat for each character]

</Characters>
```

**`bucket/speechstyles.md`** format:
```markdown
<SpeechStyles>

<characternameSpeech>
[Character Name] Speaking Style:
1. Vocabulary level: [casual/formal/technical/mixed]
2. Sentence structure: [short and punchy / long and flowing / etc.]
3. Verbal tics: [specific filler words, repeated phrases]
4. Contractions: [yes/no, which ones]
5. Exclamations: [characteristic expressions]
6. Rhetorical patterns: [questions, declarations, etc.]
7. Cultural influences: [how background affects speech]
8. Emotional expression: [how they show anger, joy, fear, etc.]
</characternameSpeech>

[Repeat for each character]

</SpeechStyles>
```

### 3. Create Technical Artifacts

**Mermaid diagrams** — Create files that visualize story relationships:
- `bucket/character-relationships.mermaid`
- `bucket/power-structure.mermaid`
- Additional diagrams as the story demands

**JSON specifications** — Create structured data files:
- `bucket/locations.json` — Detailed location data
- `bucket/[system-name].json` — Technical/magical/political systems
- Additional specs as needed

**Glossary** — Create `bucket/[universe-name]-glossary.txt`:
- One term per line: `Term - Definition`
- Organized by category
- Include all universe-specific vocabulary

### Quality Standards

- **Comprehensive**: Extract ALL relevant information from LoreBook
- **Structured**: Follow the format templates precisely
- **Consistent**: Character details match across all artifacts
- **Usable**: Each artifact should stand alone as a reference
- **Tagged**: Use XML-style tags matching the template conventions
```

---

## 15. Hook: Story Page Validation

### File: `hooks/hooks.json`

```json
{
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Write",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "If the file being written matches the pattern STORY/page*.md, verify that: (1) A bucket/ directory exists in the project with at least project-instructions.md, world.md, characters.md, and speechstyles.md files. (2) The content being written is narrative prose (not template content or empty). If bucket files are missing, respond with 'BLOCK: Cannot write story pages without a complete bucket. Run /nsi4-frameworks first.' Otherwise allow the write to proceed by responding with nothing."
          }
        ]
      }
    ]
  }
}
```

---

## 16. Script: NSL Converter

### File: `scripts/nsl-converter.py`

```python
#!/usr/bin/env python3
"""
NSL 1.1 Converter — Converts between bucket folder structure and NSL XML format.

Usage:
    python nsl-converter.py export --bucket ./bucket --story ./STORY --output story.nsl
    python nsl-converter.py import --input story.nsl --bucket ./bucket --story ./STORY
"""

import argparse
import os
import sys
import json
import re
from datetime import datetime
from xml.etree.ElementTree import (
    Element, SubElement, tostring, parse, indent, ElementTree
)
from xml.dom import minidom
from pathlib import Path


def read_file(path):
    """Read a file and return its content."""
    with open(path, 'r', encoding='utf-8') as f:
        return f.read()


def write_file(path, content):
    """Write content to a file, creating directories as needed."""
    os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)


def detect_format(filename):
    """Detect file format from extension."""
    ext = Path(filename).suffix.lower()
    format_map = {
        '.md': 'markdown',
        '.txt': 'text',
        '.json': 'json',
        '.mermaid': 'mermaid',
        '.yaml': 'yaml',
        '.yml': 'yaml',
    }
    return format_map.get(ext, 'text')


def extract_title_from_lorebook(bucket_path):
    """Extract story title from LoreBook.md."""
    lorebook = os.path.join(bucket_path, 'LoreBook.md')
    if os.path.exists(lorebook):
        content = read_file(lorebook)
        match = re.search(r'#\s*LoreBook:\s*(.+)', content)
        if match:
            return match.group(1).strip()
    return 'Untitled Story Project'


def extract_tag_content(content, tag):
    """Extract content between XML-style tags in markdown files."""
    pattern = rf'<{tag}>(.*?)</{tag}>'
    match = re.search(pattern, content, re.DOTALL)
    return match.group(1).strip() if match else content


def export_bucket(bucket_path, story_path, output_path):
    """Export bucket folder + story pages to NSL 1.1 XML file."""

    title = extract_title_from_lorebook(bucket_path)
    now = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

    # Root element
    root = Element('NarrativeBucket', version='1.1',
                   xmlns='http://narrative-spittoon.org/nsl/1.1')

    # --- Metadata ---
    metadata = SubElement(root, 'Metadata')
    SubElement(metadata, 'Title').text = title
    SubElement(metadata, 'Created').text = now
    SubElement(metadata, 'Modified').text = now
    SubElement(metadata, 'StoryStructure').text = '6-page-inversion'

    # --- ProjectManifest ---
    manifest = SubElement(root, 'ProjectManifest')
    manifest_file = os.path.join(bucket_path, 'project-instructions.md')
    if os.path.exists(manifest_file):
        overview = SubElement(manifest, 'Overview')
        overview.text = read_file(manifest_file)
    else:
        overview = SubElement(manifest, 'Overview')
        overview.text = f'Narrative Spittoon Inversion project: {title}'

    # --- CognitiveFrameworks ---
    frameworks = SubElement(root, 'CognitiveFrameworks')

    framework_files = {
        'NarrativeSpittoon': 'NarrativeSpittoon.md',
        'GhostWritingStyle': 'GhostWritingStyle.md',
        'HolographicTutor': 'HolographicTutor.md',
    }

    for tag, filename in framework_files.items():
        filepath = os.path.join(bucket_path, filename)
        if os.path.exists(filepath):
            elem = SubElement(frameworks, tag, format='markdown')
            content_elem = SubElement(elem, 'Content')
            content = read_file(filepath)
            # Strip the outer XML-style tags if present
            content = extract_tag_content(content, tag)
            content_elem.text = content

    # --- Universe ---
    universe = SubElement(root, 'Universe')
    world_file = os.path.join(bucket_path, 'world.md')
    if os.path.exists(world_file):
        world_desc = SubElement(universe, 'WorldDescription', format='markdown')
        content = read_file(world_file)
        content = extract_tag_content(content, 'World')
        world_desc.text = content

    # --- Characters ---
    characters = SubElement(root, 'Characters')
    chars_file = os.path.join(bucket_path, 'characters.md')
    if os.path.exists(chars_file):
        content = read_file(chars_file)
        # Parse individual character blocks
        char_blocks = re.findall(r'<(\w+)>\s*(.*?)\s*</\1>', content, re.DOTALL)
        for char_name, char_content in char_blocks:
            if char_name.lower() == 'characters':
                continue
            char_elem = SubElement(characters, 'Character', id=char_name.lower())
            SubElement(char_elem, 'Name').text = char_name

            # Parse fields
            for field in ['Summary', 'Background', 'Quirks', 'Description', 'Role',
                         'Personality', 'Motivations', 'Relationships']:
                match = re.search(rf'{field}:\s*(.+?)(?=\n\w+:|$)', char_content, re.DOTALL)
                if match:
                    SubElement(char_elem, field).text = match.group(1).strip()

    # --- TechnicalSpecifications ---
    json_files = list(Path(bucket_path).glob('*.json'))
    if json_files:
        tech_specs = SubElement(root, 'TechnicalSpecifications')
        for jf in json_files:
            spec = SubElement(tech_specs, 'Specification',
                            id=jf.stem, format='json', type='data')
            SubElement(spec, 'Title').text = jf.stem.replace('-', ' ').replace('_', ' ').title()
            content_elem = SubElement(spec, 'Content')
            content_elem.text = read_file(str(jf))

    # --- VisualizationResources ---
    mermaid_files = list(Path(bucket_path).glob('*.mermaid'))
    if mermaid_files:
        viz = SubElement(root, 'VisualizationResources')
        for mf in mermaid_files:
            v = SubElement(viz, 'Visualization',
                          id=mf.stem, format='mermaid', type='diagram')
            SubElement(v, 'Title').text = mf.stem.replace('-', ' ').replace('_', ' ').title()
            content_elem = SubElement(v, 'Content')
            content_elem.text = read_file(str(mf))

    # --- SupplementaryDocuments ---
    supp_files = []
    for ext in ['*.txt']:
        supp_files.extend(Path(bucket_path).glob(ext))
    # Also include LoreBook
    lorebook = Path(bucket_path) / 'LoreBook.md'
    if lorebook.exists():
        supp_files.append(lorebook)

    if supp_files:
        supp_docs = SubElement(root, 'SupplementaryDocuments')
        for sf in supp_files:
            doc = SubElement(supp_docs, 'Document',
                           id=sf.stem.lower(), format=detect_format(sf.name),
                           type='reference')
            SubElement(doc, 'Title').text = sf.stem.replace('-', ' ').replace('_', ' ').title()
            content_elem = SubElement(doc, 'Content')
            content_elem.text = read_file(str(sf))

    # --- StoryContent ---
    if story_path and os.path.exists(story_path):
        page_files = sorted(Path(story_path).glob('page*.md'),
                          key=lambda p: int(re.search(r'(\d+)', p.stem).group(1))
                          if re.search(r'(\d+)', p.stem) else 0)

        if page_files:
            story = SubElement(root, 'StoryContent', type='single')
            narrative = SubElement(story, 'SingleNarrative', structure='6-page-inversion')

            struct_meta = SubElement(narrative, 'StructureMetadata')
            SubElement(struct_meta, 'Methodology').text = 'reverse-chronological'
            SubElement(struct_meta, 'StartingPage').text = str(len(page_files) - 1)
            gen_order = ','.join(str(len(page_files) - 1 - i) for i in range(len(page_files)))
            SubElement(struct_meta, 'GenerationOrder').text = gen_order

            pages = SubElement(narrative, 'Pages')
            for pf in page_files:
                page_num = int(re.search(r'(\d+)', pf.stem).group(1))
                page = SubElement(pages, 'Page', number=str(page_num), status='completed')

                content = read_file(str(pf))

                # Extract title if present
                title_match = re.search(r'^#\s*Page\s*\d+:\s*(.+)', content, re.MULTILINE)
                if title_match:
                    SubElement(page, 'Title').text = title_match.group(1).strip()

                content_elem = SubElement(page, 'Content', format='markdown')
                content_elem.text = content

                page_meta = SubElement(page, 'Metadata')
                SubElement(page_meta, 'WordCount').text = str(len(content.split()))

    # --- Write output ---
    indent(root)
    tree = ElementTree(root)

    # Use minidom for prettier output
    xml_str = tostring(root, encoding='unicode', xml_declaration=True)
    dom = minidom.parseString(xml_str)
    pretty_xml = dom.toprettyxml(indent='  ', encoding='UTF-8').decode('utf-8')

    write_file(output_path, pretty_xml)
    print(f'Exported to: {output_path}')
    print(f'File size: {os.path.getsize(output_path):,} bytes')


def import_nsl(input_path, bucket_path, story_path):
    """Import an NSL 1.1 XML file into bucket folder + story pages."""

    tree = parse(input_path)
    root = tree.getroot()

    # Handle namespace
    ns = ''
    ns_match = re.match(r'\{(.+)\}', root.tag)
    if ns_match:
        ns = f'{{{ns_match.group(1)}}}'

    def find(parent, tag):
        """Find element with or without namespace."""
        elem = parent.find(f'{ns}{tag}')
        if elem is None:
            elem = parent.find(tag)
        return elem

    def findall(parent, tag):
        """Find all elements with or without namespace."""
        elems = parent.findall(f'{ns}{tag}')
        if not elems:
            elems = parent.findall(tag)
        return elems

    os.makedirs(bucket_path, exist_ok=True)
    os.makedirs(story_path, exist_ok=True)

    files_created = []

    # --- Extract CognitiveFrameworks ---
    frameworks = find(root, 'CognitiveFrameworks')
    if frameworks is not None:
        for tag in ['NarrativeSpittoon', 'GhostWritingStyle', 'HolographicTutor']:
            elem = find(frameworks, tag)
            if elem is not None:
                content_elem = find(elem, 'Content')
                content = content_elem.text if content_elem is not None else (elem.text or '')
                filepath = os.path.join(bucket_path, f'{tag}.md')
                write_file(filepath, f'<{tag}>\n{content.strip()}\n</{tag}>\n')
                files_created.append(filepath)

    # --- Extract Universe ---
    universe = find(root, 'Universe')
    if universe is not None:
        world_desc = find(universe, 'WorldDescription')
        if world_desc is not None:
            content = world_desc.text or ''
            filepath = os.path.join(bucket_path, 'world.md')
            write_file(filepath, f'<World>\n{content.strip()}\n</World>\n')
            files_created.append(filepath)

    # --- Extract Characters ---
    characters = find(root, 'Characters')
    if characters is not None:
        char_content = '<Characters>\n'
        for char in findall(characters, 'Character'):
            char_id = char.get('id', 'unknown')
            name_elem = find(char, 'Name')
            name = name_elem.text if name_elem is not None else char_id

            char_content += f'\n<{name}>\n'
            for field in ['Summary', 'Background', 'Quirks', 'Description', 'Role',
                         'Personality', 'Motivations', 'Relationships']:
                field_elem = find(char, field)
                if field_elem is not None and field_elem.text:
                    char_content += f'{field}: {field_elem.text.strip()}\n'
            char_content += f'</{name}>\n'

        char_content += '\n</Characters>\n'
        filepath = os.path.join(bucket_path, 'characters.md')
        write_file(filepath, char_content)
        files_created.append(filepath)

    # --- Extract TechnicalSpecifications ---
    tech_specs = find(root, 'TechnicalSpecifications')
    if tech_specs is not None:
        for spec in findall(tech_specs, 'Specification'):
            spec_id = spec.get('id', 'spec')
            fmt = spec.get('format', 'json')
            content_elem = find(spec, 'Content')
            if content_elem is not None and content_elem.text:
                ext = '.json' if fmt == 'json' else f'.{fmt}'
                filepath = os.path.join(bucket_path, f'{spec_id}{ext}')
                write_file(filepath, content_elem.text.strip())
                files_created.append(filepath)

    # --- Extract VisualizationResources ---
    viz = find(root, 'VisualizationResources')
    if viz is not None:
        for v in findall(viz, 'Visualization'):
            v_id = v.get('id', 'diagram')
            fmt = v.get('format', 'mermaid')
            content_elem = find(v, 'Content')
            if content_elem is not None and content_elem.text:
                ext = '.mermaid' if fmt == 'mermaid' else f'.{fmt}'
                filepath = os.path.join(bucket_path, f'{v_id}{ext}')
                write_file(filepath, content_elem.text.strip())
                files_created.append(filepath)

    # --- Extract SupplementaryDocuments ---
    supp = find(root, 'SupplementaryDocuments')
    if supp is not None:
        for doc in findall(supp, 'Document'):
            doc_id = doc.get('id', 'document')
            fmt = doc.get('format', 'text')
            content_elem = find(doc, 'Content')
            if content_elem is not None and content_elem.text:
                ext_map = {'markdown': '.md', 'text': '.txt', 'json': '.json'}
                ext = ext_map.get(fmt, '.txt')
                filepath = os.path.join(bucket_path, f'{doc_id}{ext}')
                write_file(filepath, content_elem.text.strip())
                files_created.append(filepath)

    # --- Extract StoryContent ---
    story_content = find(root, 'StoryContent')
    if story_content is not None:
        # Handle single narrative
        single = find(story_content, 'SingleNarrative')
        if single is not None:
            pages_elem = find(single, 'Pages')
            if pages_elem is not None:
                for page in findall(pages_elem, 'Page'):
                    page_num = page.get('number', '0')
                    content_elem = find(page, 'Content')
                    if content_elem is not None and content_elem.text:
                        filepath = os.path.join(story_path, f'page{page_num}.md')
                        write_file(filepath, content_elem.text.strip())
                        files_created.append(filepath)

        # Handle series/volumes
        volumes = find(story_content, 'Volumes')
        if volumes is not None:
            for volume in findall(volumes, 'Volume'):
                vol_num = volume.get('number', '1')
                vol_dir = os.path.join(story_path, f'volume{vol_num}')
                os.makedirs(vol_dir, exist_ok=True)

                pages_elem = find(volume, 'Pages')
                if pages_elem is not None:
                    for page in findall(pages_elem, 'Page'):
                        page_num = page.get('number', '0')
                        content_elem = find(page, 'Content')
                        if content_elem is not None and content_elem.text:
                            filepath = os.path.join(vol_dir, f'page{page_num}.md')
                            write_file(filepath, content_elem.text.strip())
                            files_created.append(filepath)

    # --- Generate project-instructions.md ---
    manifest_content = generate_manifest(bucket_path)
    manifest_path = os.path.join(bucket_path, 'project-instructions.md')
    write_file(manifest_path, manifest_content)
    files_created.append(manifest_path)

    print(f'Imported from: {input_path}')
    print(f'Files created: {len(files_created)}')
    for f in files_created:
        print(f'  {f}')


def generate_manifest(bucket_path):
    """Generate a project-instructions.md from bucket contents."""
    files = sorted(os.listdir(bucket_path))

    frameworks = []
    universe = []
    characters = []
    tech = []
    viz = []
    other = []

    framework_names = ['NarrativeSpittoon.md', 'GhostWritingStyle.md', 'HolographicTutor.md']
    char_names = ['characters.md', 'Characters.md', 'speechstyles.md', 'SpeechStyles.md']
    world_names = ['world.md', 'World.md']

    for f in files:
        if f in framework_names:
            frameworks.append(f)
        elif f in world_names or f.endswith('-glossary.txt'):
            universe.append(f)
        elif f in char_names:
            characters.append(f)
        elif f.endswith('.json'):
            tech.append(f)
        elif f.endswith('.mermaid'):
            viz.append(f)
        elif f not in ['project-instructions.md', 'LoreBook.md']:
            other.append(f)

    lines = ['# Project Instructions\n']

    if frameworks:
        lines.append('\n## Cognitive Framework Definition')
        for f in frameworks:
            lines.append(f'- {f}')

    if universe:
        lines.append('\n## Universe Core Documentation')
        for f in universe:
            lines.append(f'- {f}')

    if characters:
        lines.append('\n## Character Profiles')
        for f in characters:
            lines.append(f'- {f}')

    if tech:
        lines.append('\n## Technical Specifications')
        for f in tech:
            lines.append(f'- {f}')

    if viz:
        lines.append('\n## Visualization Resources')
        for f in viz:
            lines.append(f'- {f}')

    if other:
        lines.append('\n## Other Files')
        for f in other:
            lines.append(f'- {f}')

    lines.append('\n## Content Structure Tags')
    lines.append('- The setting is defined inside "world.md"')
    lines.append('- Character personality definitions are in "characters.md"')
    lines.append('- Speech patterns are defined in "speechstyles.md"')

    lines.append('\n## Processing Framework')
    lines.append('- Cross-referenced document relationships')
    lines.append('- Technical specification integration')
    lines.append('- Visualization resource utilization')

    return '\n'.join(lines) + '\n'


def main():
    parser = argparse.ArgumentParser(
        description='NSL 1.1 Converter — Convert between bucket folders and NSL XML format'
    )
    subparsers = parser.add_subparsers(dest='command', help='Operation to perform')

    # Export subcommand
    export_parser = subparsers.add_parser('export', help='Export bucket to NSL XML')
    export_parser.add_argument('--bucket', required=True, help='Path to bucket/ directory')
    export_parser.add_argument('--story', default=None, help='Path to STORY/ directory')
    export_parser.add_argument('--output', required=True, help='Output .nsl file path')

    # Import subcommand
    import_parser = subparsers.add_parser('import', help='Import NSL XML to bucket')
    import_parser.add_argument('--input', required=True, help='Input .nsl file path')
    import_parser.add_argument('--bucket', required=True, help='Output bucket/ directory')
    import_parser.add_argument('--story', default='./STORY', help='Output STORY/ directory')

    args = parser.parse_args()

    if args.command == 'export':
        export_bucket(args.bucket, args.story, args.output)
    elif args.command == 'import':
        import_nsl(args.input, args.bucket, args.story)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()
```

---

## 17. Reference Files

### Summary of Reference Files

| File | Location | Purpose |
|------|----------|---------|
| `nsi4-process-guide.md` | `skills/nsi4-workflow/references/` | Quick-reference workflow guide with validation checklists |
| `nsl-1.1-specification.md` | `skills/nsi4-workflow/references/` | Copy of complete NSL 1.1 spec for skill context |
| `heros-journey-mapping.md` | `skills/nsi4-workflow/references/` | Detailed Hero's Journey stage mapping for all page counts |
| `refinement-passes.md` | `skills/nsi4-workflow/references/` | Detailed instructions for each Phase 5 refinement pass |
| `cognitive-frameworks.md` | `skills/nsi4-workflow/references/` | Reference guide for all three cognitive frameworks |

The content for each reference file is specified in Section 5 above (under the skill definition). The `nsl-1.1-specification.md` reference is a copy of `docs/NSL-1.1-specification.md`.

---

## 18. Bucket Templates

The existing files in `narrative-spittoon-standard/bucket/` serve as templates that `/nsi4-start` copies into new projects. These files remain unchanged:

| Template File | Purpose |
|---|---|
| `Characters.md` | Character profile template with XML tags and field placeholders |
| `SpeechStyles.md` | Speech style template with example patterns |
| `World.md` | World-building template with XML tags |
| `NarrativeSpittoon.md` | Cognitive framework (ready to use, not a template) |
| `GhostWritingStyle.md` | Cognitive framework (ready to use, not a template) |
| `HolographicTutor.md` | Cognitive framework (ready to use, not a template) |
| `project-instructions.md` | Manifest template with placeholder sections |

---

## 19. Implementation Sequence

### Build Order

Execute these steps in order. Each step depends on previous steps being complete.

#### Step 1: Create Plugin Structure
1. Create `.claude-plugin/` directory
2. Create `plugin.json` manifest
3. Create `commands/`, `agents/`, `skills/nsi4-workflow/`, `skills/nsi4-workflow/references/`, `hooks/`, `scripts/` directories

#### Step 2: Create the Skill
1. Write `skills/nsi4-workflow/SKILL.md`
2. Write all 5 reference files in `skills/nsi4-workflow/references/`
3. Copy `docs/NSL-1.1-specification.md` → `skills/nsi4-workflow/references/nsl-1.1-specification.md`

#### Step 3: Create Commands (in workflow order)
1. Write `commands/nsi4-start.md`
2. Write `commands/nsi4-interview.md`
3. Write `commands/nsi4-bucket.md`
4. Write `commands/nsi4-frameworks.md`
5. Write `commands/nsi4-generate.md`
6. Write `commands/nsi4-refine.md`
7. Write `commands/nsi4-export.md`

#### Step 4: Create Agents
1. Write `agents/holographic-tutor.md`
2. Write `agents/bucket-builder.md`

#### Step 5: Create Hook
1. Write `hooks/hooks.json`

#### Step 6: Create NSL Converter Script
1. Write `scripts/nsl-converter.py`
2. Make executable (`chmod +x`)

#### Step 7: Create CLAUDE.md
1. Write project CLAUDE.md at plugin root describing the plugin

#### Step 8: Validation
1. Run plugin-validator agent
2. Run skill-reviewer agent on nsi4-workflow skill
3. Fix any issues

### Estimated File Count

| Category | Files | Total |
|----------|-------|-------|
| Manifest | 1 | 1 |
| Skill + References | 6 | 7 |
| Commands | 7 | 14 |
| Agents | 2 | 16 |
| Hooks | 1 | 17 |
| Scripts | 1 | 18 |
| CLAUDE.md | 1 | 19 |
| Existing templates | 7 | — |
| Existing docs | 2 | — |

**New files to create: 19**

---

## 20. Testing Plan

### Smoke Tests

1. **Plugin loads**: Verify plugin.json is recognized by Claude Code
2. **Skill triggers**: Ask "How does Narrative Spittoon Inversion work?" — skill should activate
3. **Commands visible**: All 7 commands appear in /help

### Functional Tests

| Test | Command | Expected |
|------|---------|----------|
| Project init | `/nsi4-start test-project` | Creates bucket/ and STORY/ with templates |
| Interview start | `/nsi4-interview` | Asks first question, creates LoreBook.md |
| Interview resume | `/nsi4-interview resume` | Continues from last question |
| Bucket creation | `/nsi4-bucket` | Generates world.md, characters.md, speechstyles.md |
| Technical artifacts | `/nsi4-bucket technical` | Generates JSON, mermaid, glossary files |
| Framework install | `/nsi4-frameworks` | Verifies frameworks, generates manifest |
| Generate start | `/nsi4-generate` | Loads bucket, asks about page5, begins generation |
| Generate single | `/nsi4-generate 3` | Generates only page3.md |
| Refine score | `/nsi4-refine score` | Scores each page using holographic-tutor |
| Refine all | `/nsi4-refine all` | Runs all passes in order |
| Export | `/nsi4-export export` | Creates .nsl XML file |
| Import | `/nsi4-export import test.nsl` | Extracts .nsl to bucket folder |

### Agent Tests

| Test | Trigger | Expected |
|------|---------|----------|
| Tutor Score | "Score page 3 of my story" | holographic-tutor activates with Score function |
| Tutor Review | "Review my story's dialogue quality" | holographic-tutor activates with Review function |
| Tutor Critic | "Is my story publishable?" | holographic-tutor activates with Critic function |
| Bucket Builder | "Distill my LoreBook into artifacts" | bucket-builder activates |

### Hook Tests

| Test | Action | Expected |
|------|--------|----------|
| Missing bucket | Write to STORY/page0.md without bucket | Hook blocks write with error message |
| Complete bucket | Write to STORY/page0.md with full bucket | Write proceeds normally |
| Non-story write | Write to any other file | Hook does not interfere |

### NSL Converter Tests

```bash
# Export test
python3 scripts/nsl-converter.py export --bucket ./bucket --story ./STORY --output test.nsl

# Verify XML is well-formed
python3 -c "from xml.etree.ElementTree import parse; parse('test.nsl')"

# Import test (round-trip)
mkdir test-import
python3 scripts/nsl-converter.py import --input test.nsl --bucket ./test-import/bucket --story ./test-import/STORY

# Verify files extracted
ls test-import/bucket/
ls test-import/STORY/
```

---

## Appendix: CLAUDE.md

### File: `CLAUDE.md`

```markdown
# Narrative Spittoon Inversion 4.0 Plugin

## Overview

This is a Claude Code plugin implementing the Narrative Spittoon Inversion (NSI) 4.0 workflow — an AI-assisted story creation methodology using reverse chronological generation.

## Commands

- `/nsi4-start [name]` — Initialize project structure
- `/nsi4-interview` — 20-question LoreBook interview
- `/nsi4-bucket` — Distill LoreBook into artifacts
- `/nsi4-frameworks` — Install cognitive frameworks
- `/nsi4-generate` — Reverse story generation (page5→page0)
- `/nsi4-refine [pass]` — Refinement passes
- `/nsi4-export [import|export]` — NSL 1.1 conversion

## Architecture

- `bucket/` templates are copied to new projects by /nsi4-start
- Three cognitive frameworks guide generation quality
- Story pages are generated in reverse order with approval gates
- NSL 1.1 XML format for import/export portability

## Key Files

- `skills/nsi4-workflow/SKILL.md` — Core workflow knowledge
- `scripts/nsl-converter.py` — NSL XML converter (requires Python 3.6+)
- `bucket/` — Template files for new projects
- `docs/` — Original specification documents
```

---

**End of Implementation Plan**

*Total new files to create: 19*
*Estimated implementation time: Follow build order in Section 19*
*Ready for implementation upon approval.*
